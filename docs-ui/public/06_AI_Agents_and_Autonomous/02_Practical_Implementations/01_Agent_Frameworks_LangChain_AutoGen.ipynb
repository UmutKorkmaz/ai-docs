{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Frameworks: LangChain and AutoGen\n",
    "\n",
    "This notebook provides comprehensive implementations of AI agent frameworks using LangChain and AutoGen, covering from basic agents to advanced multi-agent systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import asyncio\n",
    "from typing import List, Dict, Any, Optional, Callable\n",
    "from dataclasses import dataclass, field\n",
    "from abc import ABC, abstractmethod\n",
    "from enum import Enum\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# LangChain imports\n",
    "from langchain.agents import AgentType, Tool, AgentExecutor, initialize_agent\n",
    "from langchain.memory import ConversationBufferMemory, ConversationSummaryMemory\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain, TransformChain\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "\n",
    "# AutoGen imports\n",
    "try:\n",
    "    import autogen\n",
    "    from autogen import Agent, ConversableAgent, GroupChat, GroupChatManager\n",
    "    from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\n",
    "    from autogen.agentchat.contrib.gpt_assistant_agent import GPTAssistantAgent\n",
    "except ImportError:\n",
    "    print(\"AutoGen not available. Install with: pip install pyautogen\")\n",
    "\n",
    "# LLM imports\n",
    "try:\n",
    "    from langchain_openai import ChatOpenAI\n",
    "except ImportError:\n",
    "    from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Environment setup\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key\"  # Replace with your API key\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LangChain Agent Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTool(BaseTool):\n",
    "    \"\"\"Custom tool for LangChain agents\"\"\"\n",
    "    name: str = \"custom_tool\"\n",
    "    description: str = \"A custom tool that can perform various operations\"\n",
    "    \n",
    "    def __init__(self, func: Callable, name: str, description: str):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "        self.name = name\n",
    "        self.description = description\n",
    "    \n",
    "    def _run(self, query: str) -> str:\n",
    "        \"\"\"Run the tool\"\"\"\n",
    "        try:\n",
    "            return self.func(query)\n",
    "        except Exception as e:\n",
    "            return f\"Error: {str(e)}\"\n",
    "\n",
    "# Custom tools definitions\n",
    "def calculate_expression(expression: str) -> str:\n",
    "    \"\"\"Calculate mathematical expressions\"\"\"\n",
    "    try:\n",
    "        result = eval(expression)\n",
    "        return f\"The result of {expression} is {result}\"\n",
    "    except:\n",
    "        return \"Invalid mathematical expression\"\n",
    "\n",
    "def search_web(query: str) -> str:\n",
    "    \"\"\"Simulate web search\"\"\"\n",
    "    # This is a mock implementation\n",
    "    search_results = {\n",
    "        \"weather\": \"The weather today is sunny with 25Â°C\",\n",
    "        \"news\": \"Latest AI breakthroughs in reinforcement learning\",\n",
    "        \"sports\": \"Local team won the championship game\"\n",
    "        \"technology\": \"New AI models show promising results\"\n",
    "    }\n",
    "    \n",
    "    for key, value in search_results.items():\n",
    "        if key in query.lower():\n",
    "            return value\n",
    "    \n",
    "    return f\"No results found for '{query}'. Try searching for weather, news, sports, or technology.\"\n",
    "\n",
    "def get_time(query: str) -> str:\n",
    "    \"\"\"Get current time\"\"\"\n",
    "    current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    return f\"Current time is: {current_time}\"\n",
    "\n",
    "def save_to_file(content: str, filename: str) -> str:\n",
    "    \"\"\"Save content to file\"\"\"\n",
    "    try:\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(content)\n",
    "        return f\"Successfully saved content to {filename}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error saving file: {str(e)}\"\n",
    "\n",
    "# Create tools\n",
    "calculator_tool = CustomTool(\n",
    "    calculate_expression,\n",
    "    name=\"calculator\",\n",
    "    description=\"Useful for calculating mathematical expressions. Input should be a valid math expression like '2 + 2 * 3'\"\n",
    ")\n",
    "\n",
    "search_tool = CustomTool(\n",
    "    search_web,\n",
    "    name=\"search\",\n",
    "    description=\"Useful for searching the web for current information. Input should be a search query.\"\n",
    ")\n",
    "\n",
    "time_tool = CustomTool(\n",
    "    get_time,\n",
    "    name=\"get_time\",\n",
    "    description=\"Useful for getting the current time and date.\"\n",
    ")\n",
    "\n",
    "file_tool = CustomTool(\n",
    "    lambda x: save_to_file(x, \"output.txt\"),\n",
    "    name=\"save_file\",\n",
    "    description=\"Useful for saving content to a file named 'output.txt'.\"\n",
    ")\n",
    "\n",
    "# Tool collection\n",
    "tools = [calculator_tool, search_tool, time_tool, file_tool]\n",
    "\n",
    "class LangChainAgentFramework:\n",
    "    \"\"\"Comprehensive LangChain agent framework\"\"\"\n",
    "    \n",
    "    def __init__(self, llm, tools: List[Tool] = None):\n",
    "        self.llm = llm\n",
    "        self.tools = tools or []\n",
    "        self.agents = {}\n",
    "        self.agent_configs = {}\n",
    "        \n",
    "    def create_react_agent(self, name: str, system_prompt: str = None, memory: bool = True):\n",
    "        \"\"\"Create a ReAct agent\"\"\"\n",
    "        \n",
    "        if system_prompt is None:\n",
    "            system_prompt = \"\"\"You are a helpful AI assistant with access to various tools. \n",
    "            Use the appropriate tools to answer questions and complete tasks.\n",
    "            Always think step by step and explain your reasoning.\"\"\"\n",
    "        \n",
    "        # Set up memory if requested\n",
    "        memory_obj = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True) if memory else None\n",
    "        \n",
    "        # Create agent\n",
    "        agent = initialize_agent(\n",
    "            tools=self.tools,\n",
    "            llm=self.llm,\n",
    "            agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            verbose=True,\n",
    "            memory=memory_obj,\n",
    "            agent_kwargs={\n",
    "                \"system_message\": system_prompt,\n",
    "                \"prefix\": system_prompt\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        self.agents[name] = agent\n",
    "        self.agent_configs[name] = {\n",
    "            \"type\": \"react\",\n",
    "            \"system_prompt\": system_prompt,\n",
    "            \"memory\": memory\n",
    "        }\n",
    "        \n",
    "        return agent\n",
    "    \n",
    "    def create_conversational_agent(self, name: str, system_prompt: str = None):\n",
    "        \"\"\"Create a conversational agent\"\"\"\n",
    "        \n",
    "        if system_prompt is None:\n",
    "            system_prompt = \"\"\"You are a friendly and helpful conversational AI assistant.\n",
    "            Engage in natural conversation and help users with their questions.\n",
    "            Be conversational and engaging while providing accurate information.\"\"\"\n",
    "        \n",
    "        # Create prompt template\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            SystemMessage(content=system_prompt),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            HumanMessage(content=\"{input}\")\n",
    "        ])\n",
    "        \n",
    "        # Create memory\n",
    "        memory = ConversationBufferMemory(return_messages=True)\n",
    "        \n",
    "        # Create chain\n",
    "        chain = LLMChain(\n",
    "            llm=self.llm,\n",
    "            prompt=prompt,\n",
    "            memory=memory,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        self.agents[name] = chain\n",
    "        self.agent_configs[name] = {\n",
    "            \"type\": \"conversational\",\n",
    "            \"system_prompt\": system_prompt,\n",
    "            \"memory\": True\n",
    "        }\n",
    "        \n",
    "        return chain\n",
    "    \n",
    "    def create_planning_agent(self, name: str, system_prompt: str = None):\n",
    "        \"\"\"Create a planning and task decomposition agent\"\"\"\n",
    "        \n",
    "        if system_prompt is None:\n",
    "            system_prompt = \"\"\"You are an expert planner and task decomposition agent.\n",
    "            When given a complex task, break it down into smaller, manageable steps.\n",
    "            For each step, explain what needs to be done and why it's important.\n",
    "            Consider dependencies between steps and suggest an optimal order.\"\"\"\n",
    "        \n",
    "        # Create prompt template for planning\n",
    "        planning_prompt = PromptTemplate(\n",
    "            input_variables=[\"task\"],\n",
    "            template=\"\"\"{system_prompt}\n",
    "\n",
    "Task: {task}\n",
    "\n",
    "Please break this task down into clear steps:\n",
    "\n",
    "1. [Step 1] - [Reasoning]\n",
    "2. [Step 2] - [Reasoning]\n",
    "3. [Step 3] - [Reasoning]\n",
    "\n",
    "Consider dependencies and provide a logical sequence.\"\"\".format(\n",
    "                system_prompt=system_prompt, task=\"{task}\"\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Create planning chain\n",
    "        planning_chain = LLMChain(\n",
    "            llm=self.llm,\n",
    "            prompt=planning_prompt,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        self.agents[name] = planning_chain\n",
    "        self.agent_configs[name] = {\n",
    "            \"type\": \"planning\",\n",
    "            \"system_prompt\": system_prompt,\n",
    "            \"memory\": False\n",
    "        }\n",
    "        \n",
    "        return planning_chain\n",
    "    \n",
    "    def create_multi_tool_agent(self, name: str, specific_tools: List[Tool] = None):\n",
    "        \"\"\"Create an agent with specific tools\"\"\"\n",
    "        \n",
    "        tools_to_use = specific_tools or self.tools\n",
    "        \n",
    "        system_prompt = \"\"\"You are a specialized tool-using agent.\n",
    "        You have access to specific tools to help you complete tasks.\n",
    "        Use the tools appropriately and explain your actions.\n",
    "        Always verify the results and provide clear explanations.\"\"\"\n",
    "        \n",
    "        agent = initialize_agent(\n",
    "            tools=tools_to_use,\n",
    "            llm=self.llm,\n",
    "            agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            verbose=True,\n",
    "            memory=ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True),\n",
    "            agent_kwargs={\"system_message\": system_prompt}\n",
    "        )\n",
    "        \n",
    "        self.agents[name] = agent\n",
    "        self.agent_configs[name] = {\n",
    "            \"type\": \"multi_tool\",\n",
    "            \"tools\": [tool.name for tool in tools_to_use],\n",
    "            \"system_prompt\": system_prompt,\n",
    "            \"memory\": True\n",
    "        }\n",
    "        \n",
    "        return agent\n",
    "    \n",
    "    def run_agent(self, agent_name: str, input_text: str):\n",
    "        \"\"\"Run a specific agent\"\"\"\n",
    "        if agent_name not in self.agents:\n",
    "            raise ValueError(f\"Agent '{agent_name}' not found\")\n",
    "        \n",
    "        agent = self.agents[agent_name]\n",
    "        config = self.agent_configs[agent_name]\n",
    "        \n",
    "        logger.info(f\"Running agent '{agent_name}' with input: {input_text}\")\n",
    "        \n",
    "        try:\n",
    "            if config[\"type\"] in [\"react\", \"multi_tool\"]:\n",
    "                result = agent.run(input_text)\n",
    "            elif config[\"type\"] == \"conversational\":\n",
    "                result = agent.predict(input=input_text)\n",
    "            elif config[\"type\"] == \"planning\":\n",
    "                result = agent.run(task=input_text)\n",
    "            else:\n",
    "                result = agent(input_text)\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error running agent '{agent_name}': {str(e)}\")\n",
    "            return f\"Error: {str(e)}\"\n",
    "    \n",
    "    def list_agents(self):\n",
    "        \"\"\"List all available agents\"\"\"\n",
    "        return list(self.agents.keys())\n",
    "    \n",
    "    def get_agent_info(self, agent_name: str):\n",
    "        \"\"\"Get information about a specific agent\"\"\"\n",
    "        if agent_name in self.agent_configs:\n",
    "            return self.agent_configs[agent_name]\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. AutoGen Agent Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoGenFramework:\n",
    "    \"\"\"Comprehensive AutoGen agent framework\"\"\"\n",
    "    \n",
    "    def __init__(self, config_list: List[Dict[str, str]] = None):\n",
    "        \"\"\"Initialize AutoGen framework\"\"\"\n",
    "        self.agents = {}\n",
    "        self.group_chats = {}\n",
    "        \n",
    "        # Default configuration\n",
    "        if config_list is None:\n",
    "            config_list = [{\n",
    "                \"model\": \"gpt-4\",\n",
    "                \"api_key\": os.environ.get(\"OPENAI_API_KEY\"),\n",
    "            }]\n",
    "        \n",
    "        self.config_list = config_list\n",
    "    \n",
    "    def create_assistant_agent(self, name: str, system_message: str, **kwargs):\n",
    "        \"\"\"Create an assistant agent\"\"\"\n",
    "        \n",
    "        default_config = {\n",
    "            \"name\": name,\n",
    "            \"system_message\": system_message,\n",
    "            \"llm_config\": {\"config_list\": self.config_list},\n",
    "            \"human_input_mode\": \"NEVER\",\n",
    "        }\n",
    "        \n",
    "        # Update with provided kwargs\n",
    "        default_config.update(kwargs)\n",
    "        \n",
    "        agent = ConversableAgent(**default_config)\n",
    "        self.agents[name] = agent\n",
    "        \n",
    "        return agent\n",
    "    \n",
    "    def create_user_proxy(self, name: str, **kwargs):\n",
    "        \"\"\"Create a user proxy agent\"\"\"\n",
    "        \n",
    "        default_config = {\n",
    "            \"name\": name,\n",
    "            \"human_input_mode\": \"NEVER\",\n",
    "            \"max_consecutive_auto_reply\": 1,\n",
    "            \"code_execution_config\": False,\n",
    "        }\n",
    "        \n",
    "        default_config.update(kwargs)\n",
    "        \n",
    "        agent = ConversableAgent(**default_config)\n",
    "        self.agents[name] = agent\n",
    "        \n",
    "        return agent\n",
    "    \n",
    "    def create_coding_agent(self, name: str, system_message: str = None, **kwargs):\n",
    "        \"\"\"Create a coding assistant agent\"\"\"\n",
    "        \n",
    "        if system_message is None:\n",
    "            system_message = \"\"\"You are a helpful AI assistant that can write and execute code.\n",
    "            When asked to solve a problem, write the code to solve it and execute it.\n",
    "            Always explain what the code does and provide the results.\"\"\"\n",
    "        \n",
    "        default_config = {\n",
    "            \"name\": name,\n",
    "            \"system_message\": system_message,\n",
    "            \"llm_config\": {\"config_list\": self.config_list},\n",
    "            \"human_input_mode\": \"NEVER\",\n",
    "            \"code_execution_config\": {\n",
    "                \"work_dir\": \"coding_workspace\",\n",
    "                \"use_docker\": False,\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        default_config.update(kwargs)\n",
    "        \n",
    "        agent = ConversableAgent(**default_config)\n",
    "        self.agents[name] = agent\n",
    "        \n",
    "        return agent\n",
    "    \n",
    "    def create_group_chat(self, name: str, agent_names: List[str], **kwargs):\n",
    "        \"\"\"Create a group chat with multiple agents\"\"\"\n",
    "        \n",
    "        # Get agents\n",
    "        agents = [self.agents[name] for name in agent_names if name in self.agents]\n",
    "        \n",
    "        if not agents:\n",
    "            raise ValueError(\"No valid agents provided for group chat\")\n",
    "        \n",
    "        # Create group chat\n",
    "        default_config = {\n",
    "            \"agents\": agents,\n",
    "            \"messages\": [],\n",
    "            \"max_round\": 50,\n",
    "        }\n",
    "        \n",
    "        default_config.update(kwargs)\n",
    "        \n",
    "        group_chat = GroupChat(**default_config)\n",
    "        \n",
    "        # Create manager\n",
    "        manager_config = kwargs.get(\"manager_config\", {})\n",
    "        manager = GroupChatManager(groupchat=group_chat, **manager_config)\n",
    "        \n",
    "        self.group_chats[name] = {\n",
    "            \"group_chat\": group_chat,\n",
    "            \"manager\": manager,\n",
    "            \"agent_names\": agent_names\n",
    "        }\n",
    "        \n",
    "        return manager\n",
    "    \n",
    "    def initiate_chat(self, agent_name: str, recipient_name: str, message: str, **kwargs):\n",
    "        \"\"\"Initiate chat between two agents\"\"\"\n",
    "        \n",
    "        if agent_name not in self.agents:\n",
    "            raise ValueError(f\"Agent '{agent_name}' not found\")\n",
    "        \n",
    "        if recipient_name not in self.agents:\n",
    "            raise ValueError(f\"Agent '{recipient_name}' not found\")\n",
    "        \n",
    "        agent = self.agents[agent_name]\n",
    "        recipient = self.agents[recipient_name]\n",
    "        \n",
    "        result = agent.initiate_chat(recipient, message=message, **kwargs)\n",
    "        return result\n",
    "    \n",
    "    def run_group_chat(self, group_name: str, initiator_name: str, message: str):\n",
    "        \"\"\"Run a group chat\"\"\"\n",
    "        \n",
    "        if group_name not in self.group_chats:\n",
    "            raise ValueError(f\"Group chat '{group_name}' not found\")\n",
    "        \n",
    "        group_info = self.group_chats[group_name]\n",
    "        \n",
    "        if initiator_name not in group_info[\"agent_names\"]:\n",
    "            raise ValueError(f\"Initiator '{initiator_name}' not in group chat\")\n",
    "        \n",
    "        initiator = self.agents[initiator_name]\n",
    "        \n",
    "        result = initiator.initiate_chat(\n",
    "            group_info[\"manager\"],\n",
    "            message=message\n",
    "        )\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def list_agents(self):\n",
    "        \"\"\"List all available agents\"\"\"\n",
    "        return list(self.agents.keys())\n",
    "    \n",
    "    def list_group_chats(self):\n",
    "        \"\"\"List all group chats\"\"\"\n",
    "        return list(self.group_chats.keys())\n",
    "\n",
    "# Example AutoGen setup\n",
    "def setup_autogen_example():\n",
    "    \"\"\"Set up example AutoGen agents and group chat\"\"\"\n",
    "    \n",
    "    # Initialize framework\n",
    "    autogen_framework = AutoGenFramework()\n",
    "    \n",
    "    # Create agents\n",
    "    planner = autogen_framework.create_assistant_agent(\n",
    "        \"planner\",\n",
    "        system_message=\"\"\"You are a project planning expert. \n",
    "        Break down complex projects into manageable tasks and create detailed plans.\n",
    "        Consider timelines, resources, and dependencies.\"\"\"\n",
    "    )\n",
    "    \n",
    "    coder = autogen_framework.create_coding_agent(\n",
    "        \"coder\",\n",
    "        system_message=\"\"\"You are an expert programmer. \n",
    "        Write clean, efficient code and explain your solutions.\n",
    "        Test your code and ensure it works correctly.\"\"\"\n",
    "    )\n",
    "    \n",
    "    reviewer = autogen_framework.create_assistant_agent(\n",
    "        \"reviewer\",\n",
    "        system_message=\"\"\"You are a code reviewer. \n",
    "        Review code for quality, efficiency, and best practices.\n",
    "        Provide constructive feedback and suggest improvements.\"\"\"\n",
    "    )\n",
    "    \n",
    "    user_proxy = autogen_framework.create_user_proxy(\n",
    "        \"user_proxy\",\n",
    "        max_consecutive_auto_reply=0\n",
    "    )\n",
    "    \n",
    "    # Create group chat\n",
    "    project_team = autogen_framework.create_group_chat(\n",
    "        \"project_team\",\n",
    "        [\"planner\", \"coder\", \"reviewer\"],\n",
    "        max_round=20\n",
    "    )\n",
    "    \n",
    "    return autogen_framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Advanced Multi-Agent Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiAgentSystem:\n",
    "    \"\"\"Advanced multi-agent system with coordination and communication\"\"\"\n",
    "    \n",
    "    def __init__(self, langchain_framework, autogen_framework):\n",
    "        self.langchain = langchain_framework\n",
    "        self.autogen = autogen_framework\n",
    "        self.agent_network = {}\n",
    "        self.workflow_engine = WorkflowEngine()\n",
    "        \n",
    "    def create_specialized_agents(self):\n",
    "        \"\"\"Create specialized agents for different tasks\"\"\"\n",
    "        \n",
    "        # Research agent\n",
    "        research_agent = self.langchain.create_react_agent(\n",
    "            \"researcher\",\n",
    "            system_prompt=\"\"\"You are a research specialist with access to search tools.\n",
    "            Conduct thorough research on topics and provide comprehensive summaries.\n",
    "            Always cite sources and verify information.\"\"\"\n",
    "        )\n",
    "        \n",
    "        # Analysis agent\n",
    "        analysis_agent = self.langchain.create_conversational_agent(\n",
    "            \"analyst\",\n",
    "            system_prompt=\"\"\"You are a data analysis expert.\n",
    "            Analyze information, identify patterns, and provide insights.\n",
    "            Use logical reasoning and evidence-based conclusions.\"\"\"\n",
    "        )\n",
    "        \n",
    "        # Strategy agent\n",
    "        strategy_agent = self.langchain.create_planning_agent(\n",
    "            \"strategist\",\n",
    "            system_prompt=\"\"\"You are a strategic planning expert.\n",
    "            Develop comprehensive strategies and action plans.\n",
    "            Consider long-term implications and multiple scenarios.\"\"\"\n",
    "        )\n",
    "        \n",
    "        # Implementation agent\n",
    "        implementation_agent = self.langchain.create_multi_tool_agent(\n",
    "            \"implementer\",\n",
    "            specific_tools=[calculator_tool, file_tool]\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"researcher\": research_agent,\n",
    "            \"analyst\": analysis_agent,\n",
    "            \"strategist\": strategy_agent,\n",
    "            \"implementer\": implementation_agent\n",
    "        }\n",
    "    \n",
    "    def create_agent_workflow(self, workflow_name: str, agents: Dict[str, Any], workflow_config: Dict):\n",
    "        \"\"\"Create a workflow with multiple agents\"\"\"\n",
    "        \n",
    "        workflow = {\n",
    "            \"name\": workflow_name,\n",
    "            \"agents\": agents,\n",
    "            \"steps\": workflow_config.get(\"steps\", []),\n",
    "            \"dependencies\": workflow_config.get(\"dependencies\", {}),\n",
    "            \"output_format\": workflow_config.get(\"output_format\", \"summary\")\n",
    "        }\n",
    "        \n",
    "        self.agent_network[workflow_name] = workflow\n",
    "        return workflow\n",
    "    \n",
    "    def execute_workflow(self, workflow_name: str, input_data: Dict):\n",
    "        \"\"\"Execute a multi-agent workflow\"\"\"\n",
    "        \n",
    "        if workflow_name not in self.agent_network:\n",
    "            raise ValueError(f\"Workflow '{workflow_name}' not found\")\n",
    "        \n",
    "        workflow = self.agent_network[workflow_name]\n",
    "        agents = workflow[\"agents\"]\n",
    "        steps = workflow[\"steps\"]\n",
    "        \n",
    "        results = {}\n",
    "        context = {\"input\": input_data}\n",
    "        \n",
    "        for step in steps:\n",
    "            agent_name = step[\"agent\"]\n",
    "            task = step[\"task\"]\n",
    "            \n",
    "            if agent_name not in agents:\n",
    "                logger.error(f\"Agent '{agent_name}' not found in workflow\")\n",
    "                continue\n",
    "            \n",
    "            # Prepare input for agent\n",
    "            agent_input = self._prepare_agent_input(task, context)\n",
    "            \n",
    "            # Execute agent\n",
    "            logger.info(f\"Executing agent '{agent_name}' for task: {task}\")\n",
    "            result = self.langchain.run_agent(agent_name, agent_input)\n",
    "            \n",
    "            # Store result\n",
    "            results[step[\"output_key\"]] = result\n",
    "            context[step[\"output_key\"]] = result\n",
    "            \n",
    "            logger.info(f\"Agent '{agent_name}' completed task\")\n",
    "        \n",
    "        # Format final output\n",
    "        final_output = self._format_workflow_output(results, workflow[\"output_format\"])\n",
    "        \n",
    "        return final_output\n",
    "    \n",
    "    def _prepare_agent_input(self, task: str, context: Dict) -> str:\n",
    "        \"\"\"Prepare input for agent execution\"\"\"\n",
    "        \n",
    "        # Replace placeholders in task with context values\n",
    "        for key, value in context.items():\n",
    "            task = task.replace(f\"{{{key}}}\", str(value))\n",
    "        \n",
    "        return task\n",
    "    \n",
    "    def _format_workflow_output(self, results: Dict, output_format: str) -> str:\n",
    "        \"\"\"Format workflow output according to specified format\"\"\"\n",
    "        \n",
    "        if output_format == \"summary\":\n",
    "            summary_parts = []\n",
    "            for key, value in results.items():\n",
    "                summary_parts.append(f\"{key}: {value}\")\n",
    "            return \"\\n\\n\".join(summary_parts)\n",
    "        \n",
    "        elif output_format == \"detailed\":\n",
    "            detailed_output = f\"Workflow Results:\\n\\n\"\n",
    "            for key, value in results.items():\n",
    "                detailed_output += f\"{key}:\\n{value}\\n\\n\"\n",
    "            return detailed_output\n",
    "        \n",
    "        else:\n",
    "            return str(results)\n",
    "\n",
    "class WorkflowEngine:\n",
    "    \"\"\"Workflow engine for managing multi-agent workflows\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.workflows = {}\n",
    "        self.execution_history = []\n",
    "    \n",
    "    def register_workflow(self, name: str, workflow_config: Dict):\n",
    "        \"\"\"Register a workflow\"\"\"\n",
    "        self.workflows[name] = workflow_config\n",
    "    \n",
    "    def execute_workflow(self, name: str, input_data: Dict):\n",
    "        \"\"\"Execute a registered workflow\"\"\"\n",
    "        \n",
    "        if name not in self.workflows:\n",
    "            raise ValueError(f\"Workflow '{name}' not registered\")\n",
    "        \n",
    "        workflow = self.workflows[name]\n",
    "        \n",
    "        execution_record = {\n",
    "            \"workflow_name\": name,\n",
    "            \"input_data\": input_data,\n",
    "            \"start_time\": datetime.now(),\n",
    "            \"steps\": []\n",
    "            \"status\": \"running\"\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            results = self._execute_workflow_steps(workflow, input_data, execution_record)\n",
    "            execution_record[\"status\"] = \"completed\"\n",
    "            execution_record[\"results\"] = results\n",
    "            execution_record[\"end_time\"] = datetime.now()\n",
    "            \n",
    "        except Exception as e:\n",
    "            execution_record[\"status\"] = \"failed\"\n",
    "            execution_record[\"error\"] = str(e)\n",
    "            execution_record[\"end_time\"] = datetime.now()\n",
    "            \n",
    "            logger.error(f\"Workflow execution failed: {str(e)}\")\n",
    "            \n",
    "        self.execution_history.append(execution_record)\n",
    "        return execution_record\n",
    "    \n",
    "    def _execute_workflow_steps(self, workflow: Dict, input_data: Dict, execution_record: Dict):\n",
    "        \"\"\"Execute workflow steps\"\"\"\n",
    "        \n",
    "        results = {}\n",
    "        context = input_data.copy()\n",
    "        \n",
    "        for step in workflow[\"steps\"]:\n",
    "            step_record = {\n",
    "                \"step_name\": step[\"name\"],\n",
    "                \"start_time\": datetime.now(),\n",
    "                \"status\": \"running\"\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                # Check dependencies\n",
    "                if self._check_dependencies(step, results):\n",
    "                    # Execute step\n",
    "                    step_result = self._execute_step(step, context)\n",
    "                    results[step[\"output_key\"]] = step_result\n",
    "                    context[step[\"output_key\"]] = step_result\n",
    "                    \n",
    "                    step_record[\"status\"] = \"completed\"\n",
    "                    step_record[\"result\"] = step_result\n",
    "                else:\n",
    "                    step_record[\"status\"] = \"skipped\"\n",
    "                    step_record[\"reason\"] = \"Dependencies not met\"\n",
    "                \n",
    "            except Exception as e:\n",
    "                step_record[\"status\"] = \"failed\"\n",
    "                step_record[\"error\"] = str(e)\n",
    "                \n",
    "                logger.error(f\"Step '{step['name']}' failed: {str(e)}\")\n",
    "                \n",
    "                if workflow.get(\"fail_fast\", False):\n",
    "                    raise e\n",
    "            \n",
    "            step_record[\"end_time\"] = datetime.now()\n",
    "            execution_record[\"steps\"].append(step_record)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _check_dependencies(self, step: Dict, results: Dict) -> bool:\n",
    "        \"\"\"Check if step dependencies are satisfied\"\"\"\n",
    "        \n",
    "        dependencies = step.get(\"dependencies\", [])\n",
    "        \n",
    "        for dep in dependencies:\n",
    "            if dep not in results:\n",
    "                return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def _execute_step(self, step: Dict, context: Dict) -> Any:\n",
    "        \"\"\"Execute a single workflow step\"\"\"\n",
    "        \n",
    "        step_type = step[\"type\"]\n",
    "        \n",
    "        if step_type == \"agent\":\n",
    "            # This would integrate with the agent framework\n",
    "            agent_name = step[\"agent\"]\n",
    "            task = step[\"task\"].format(**context)\n",
    "            \n",
    "            # Placeholder for agent execution\n",
    "            return f\"Agent '{agent_name}' executed task: {task}\"\n",
    "        \n",
    "        elif step_type == \"transform\":\n",
    "            # Data transformation step\n",
    "            transform_func = step[\"function\"]\n",
    "            input_data = context[step[\"input\"]]\n",
    "            return transform_func(input_data)\n",
    "        \n",
    "        elif step_type == \"condition\":\n",
    "            # Conditional step\n",
    "            condition = step[\"condition\"]\n",
    "            return eval(condition, {}, context)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown step type: {step_type}\")\n",
    "    \n",
    "    def get_execution_history(self, workflow_name: str = None) -> List[Dict]:\n",
    "        \"\"\"Get execution history\"\"\"\n",
    "        \n",
    "        if workflow_name:\n",
    "            return [record for record in self.execution_history \n",
    "                    if record[\"workflow_name\"] == workflow_name]\n",
    "        \n",
    "        return self.execution_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Agent Memory and Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentMemorySystem:\n",
    "    \"\"\"Advanced memory system for AI agents\"\"\"\n",
    "    \n",
    "    def __init__(self, max_short_term: int = 1000, max_long_term: int = 10000):\n",
    "        self.short_term_memory = []  # Recent interactions\n",
    "        self.long_term_memory = []   # Persistent knowledge\n",
    "        self.episodic_memory = []    # Specific episodes/contexts\n",
    "        self.semantic_memory = {}    # Facts and concepts\n",
    "        \n",
    "        self.max_short_term = max_short_term\n",
    "        self.max_long_term = max_long_term\n",
    "        \n",
    "        # Memory indices\n",
    "        self.semantic_index = {}\n",
    "        self.episodic_index = {}\n",
    "    \n",
    "    def add_short_term_memory(self, memory: Dict):\n",
    "        \"\"\"Add to short-term memory\"\"\"\n",
    "        memory[\"timestamp\"] = datetime.now()\n",
    "        memory[\"id\"] = len(self.short_term_memory)\n",
    "        \n",
    "        self.short_term_memory.append(memory)\n",
    "        \n",
    "        # Maintain size limit\n",
    "        if len(self.short_term_memory) > self.max_short_term:\n",
    "            # Move oldest to long-term memory\n",
    "            old_memory = self.short_term_memory.pop(0)\n",
    "            self.add_long_term_memory(old_memory)\n",
    "    \n",
    "    def add_long_term_memory(self, memory: Dict):\n",
    "        \"\"\"Add to long-term memory\"\"\"\n",
    "        memory[\"timestamp\"] = datetime.now()\n",
    "        memory[\"id\"] = len(self.long_term_memory)\n",
    "        \n",
    "        self.long_term_memory.append(memory)\n",
    "        \n",
    "        # Maintain size limit\n",
    "        if len(self.long_term_memory) > self.max_long_term:\n",
    "            self.long_term_memory.pop(0)\n",
    "    \n",
    "    def add_episodic_memory(self, episode: Dict):\n",
    "        \"\"\"Add episodic memory\"\"\"\n",
    "        episode[\"timestamp\"] = datetime.now()\n",
    "        episode[\"id\"] = len(self.episodic_memory)\n",
    "        \n",
    "        self.episodic_memory.append(episode)\n",
    "        \n",
    "        # Index episode\n",
    "        keywords = self._extract_keywords(episode)\n",
    "        for keyword in keywords:\n",
    "            if keyword not in self.episodic_index:\n",
    "                self.episodic_index[keyword] = []\n",
    "            self.episodic_index[keyword].append(episode[\"id\"])\n",
    "    \n",
    "    def add_semantic_memory(self, concept: str, knowledge: Dict):\n",
    "        \"\"\"Add semantic memory (facts and concepts)\"\"\"\n",
    "        knowledge[\"concept\"] = concept\n",
    "        knowledge[\"timestamp\"] = datetime.now()\n",
    "        \n",
    "        self.semantic_memory[concept] = knowledge\n",
    "        \n",
    "        # Index semantic memory\n",
    "        keywords = self._extract_keywords(knowledge)\n",
    "        for keyword in keywords:\n",
    "            if keyword not in self.semantic_index:\n",
    "                self.semantic_index[keyword] = []\n",
    "            self.semantic_index[keyword].append(concept)\n",
    "    \n",
    "    def retrieve_relevant_memories(self, query: str, limit: int = 5) -> List[Dict]:\n",
    "        \"\"\"Retrieve memories relevant to query\"\"\"\n",
    "        \n",
    "        # Extract keywords from query\n",
    "        query_keywords = self._extract_keywords({\"query\": query})\n",
    "        \n",
    "        relevant_memories = []\n",
    "        memory_scores = {}\n",
    "        \n",
    "        # Search short-term memory\n",
    "        for memory in self.short_term_memory[-50:]:  # Last 50 items\n",
    "            score = self._calculate_relevance_score(query_keywords, memory)\n",
    "            if score > 0.1:\n",
    "                memory_scores[memory[\"id\"]] = (score, memory, \"short_term\")\n",
    "        \n",
    "        # Search semantic memory\n",
    "        for keyword in query_keywords:\n",
    "            if keyword in self.semantic_index:\n",
    "                for concept in self.semantic_index[keyword]:\n",
    "                    if concept in self.semantic_memory:\n",
    "                        memory = self.semantic_memory[concept]\n",
    "                        score = self._calculate_relevance_score(query_keywords, memory)\n",
    "                        memory_scores[memory[\"id\"]] = (score, memory, \"semantic\")\n",
    "        \n",
    "        # Search episodic memory\n",
    "        for keyword in query_keywords:\n",
    "            if keyword in self.episodic_index:\n",
    "                for episode_id in self.episodic_index[keyword]:\n",
    "                    if episode_id < len(self.episodic_memory):\n",
    "                        memory = self.episodic_memory[episode_id]\n",
    "                        score = self._calculate_relevance_score(query_keywords, memory)\n",
    "                        memory_scores[memory[\"id\"]] = (score, memory, \"episodic\")\n",
    "        \n",
    "        # Sort by relevance and return top memories\n",
    "        sorted_memories = sorted(memory_scores.values(), key=lambda x: x[0], reverse=True)\n",
    "        \n",
    "        return [memory[1] for memory in sorted_memories[:limit]]\n",
    "    \n",
    "    def _extract_keywords(self, text_data: Dict) -> List[str]:\n",
    "        \"\"\"Extract keywords from text data\"\"\"\n",
    "        # Simple keyword extraction\n",
    "        text = str(text_data).lower()\n",
    "        \n",
    "        # Remove common stop words\n",
    "        stop_words = {\"the\", \"a\", \"an\", \"and\", \"or\", \"but\", \"in\", \"on\", \"at\", \"to\", \"for\", \"of\", \"with\", \"by\"}\n",
    "        \n",
    "        words = text.split()\n",
    "        keywords = [word.strip(\".,?!;:'\\\"()\") for word in words if len(word) > 3 and word not in stop_words]\n",
    "        \n",
    "        return list(set(keywords))\n",
    "    \n",
    "    def _calculate_relevance_score(self, query_keywords: List[str], memory: Dict) -> float:\n",
    "        \"\"\"Calculate relevance score between query and memory\"\"\"\n",
    "        memory_keywords = self._extract_keywords(memory)\n",
    "        \n",
    "        # Simple overlap scoring\n",
    "        overlap = len(set(query_keywords) & set(memory_keywords))\n",
    "        total_keywords = len(set(query_keywords) | set(memory_keywords))\n",
    "        \n",
    "        if total_keywords == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        return overlap / total_keywords\n",
    "    \n",
    "    def consolidate_memories(self):\n",
    "        \"\"\"Consolidate short-term memories into long-term memory\"\"\"\n",
    "        \n",
    "        # Move old short-term memories to long-term\n",
    "        memories_to_consolidate = self.short_term_memory[:len(self.short_term_memory) // 2]\n",
    "        \n",
    "        for memory in memories_to_consolidate:\n",
    "            self.add_long_term_memory(memory)\n",
    "        \n",
    "        # Clear from short-term\n",
    "        self.short_term_memory = self.short_term_memory[len(memories_to_consolidate):]\n",
    "    \n",
    "    def get_memory_stats(self) -> Dict:\n",
    "        \"\"\"Get memory system statistics\"\"\"\n",
    "        return {\n",
    "            \"short_term_count\": len(self.short_term_memory),\n",
    "            \"long_term_count\": len(self.long_term_memory),\n",
    "            \"episodic_count\": len(self.episodic_memory),\n",
    "            \"semantic_count\": len(self.semantic_memory),\n",
    "            \"semantic_index_size\": len(self.semantic_index),\n",
    "            \"episodic_index_size\": len(self.episodic_index)\n",
    "        }\n",
    "\n",
    "class LearningAgent:\n",
    "    \"\"\"Agent with learning capabilities\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, memory_system: AgentMemorySystem):\n",
    "        self.name = name\n",
    "        self.memory_system = memory_system\n",
    "        self.learning_rate = 0.1\n",
    "        self.performance_history = []\n",
    "        self.adaptation_rules = []\n",
    "    \n",
    "    def learn_from_interaction(self, interaction: Dict):\n",
    "        \"\"\"Learn from agent interactions\"\"\"\n",
    "        \n",
    "        # Add to memory\n",
    "        self.memory_system.add_short_term_memory(interaction)\n",
    "        \n",
    "        # Extract learning\n",
    "        learning = self._extract_learning(interaction)\n",
    "        \n",
    "        if learning:\n",
    "            # Add to semantic memory\n",
    "            self.memory_system.add_semantic_memory(\n",
    "                f\"learned_{len(self.memory_system.semantic_memory)}\",\n",
    "                {\n",
    "                    \"type\": \"learned_rule\",\n",
    "                    \"rule\": learning,\n",
    "                    \"context\": interaction.get(\"context\", \"\"),\n",
    "                    \"confidence\": 0.8\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # Update adaptation rules\n",
    "            self.adaptation_rules.append(learning)\n",
    "            \n",
    "            logger.info(f\"Agent {self.name} learned: {learning}\")\n",
    "    \n",
    "    def adapt_behavior(self, context: Dict) -> Dict:\n",
    "        \"\"\"Adapt behavior based on learning\"\"\"\n",
    "        \n",
    "        # Retrieve relevant memories\n",
    "        relevant_memories = self.memory_system.retrieve_relevant_memories(\n",
    "            str(context), limit=3\n",
    "        )\n",
    "        \n",
    "        # Apply adaptation rules\n",
    "        adapted_behavior = context.copy()\n",
    "        \n",
    "        for memory in relevant_memories:\n",
    "            if memory.get(\"type\") == \"learned_rule\":\n",
    "                rule = memory.get(\"rule\", \"\")\n",
    "                # Apply rule (simplified)\n",
    "                if \"more_detailed\" in rule:\n",
    "                    adapted_behavior[\"detail_level\"] = adapted_behavior.get(\"detail_level\", 1) + 1\n",
    "                elif \"faster_response\" in rule:\n",
    "                    adapted_behavior[\"response_speed\"] = \"fast\"\n",
    "        \n",
    "        return adapted_behavior\n",
    "    \n",
    "    def _extract_learning(self, interaction: Dict) -> Optional[str]:\n",
    "        \"\"\"Extract learning from interaction\"\"\"\n",
    "        \n",
    "        # Simple learning extraction\n",
    "        outcome = interaction.get(\"outcome\", \"\")\n",
    "        feedback = interaction.get(\"feedback\", \"\")\n",
    "        \n",
    "        if \"positive\" in feedback.lower() and outcome == \"success\":\n",
    "            return \"Continue this approach, it was successful\"\n",
    "        elif \"negative\" in feedback.lower():\n",
    "            return \"Adjust approach, it was not well received\"\n",
    "        elif \"more detail\" in feedback.lower():\n",
    "            return \"Provide more detailed responses\"\n",
    "        elif \"faster\" in feedback.lower():\n",
    "            return \"Respond more quickly\"\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def evaluate_performance(self, metrics: Dict):\n",
    "        \"\"\"Evaluate and track performance\"\"\"\n",
    "        \n",
    "        performance_record = {\n",
    "            \"timestamp\": datetime.now(),\n",
    "            \"metrics\": metrics,\n",
    "            \"trend\": self._calculate_performance_trend(metrics)\n",
    "        }\n",
    "        \n",
    "        self.performance_history.append(performance_record)\n",
    "        \n",
    "        # Keep only recent history\n",
    "        if len(self.performance_history) > 100:\n",
    "            self.performance_history = self.performance_history[-50:]\n",
    "        \n",
    "        return performance_record\n",
    "    \n",
    "    def _calculate_performance_trend(self, current_metrics: Dict) -> str:\n",
    "        \"\"\"Calculate performance trend\"\"\"\n",
    "        \n",
    "        if len(self.performance_history) < 5:\n",
    "            return \"insufficient_data\"\n",
    "        \n",
    "        # Simple trend calculation\n",
    "        recent_performance = self.performance_history[-5:]\n",
    "        \n",
    "        # Calculate trend for each metric\n",
    "        trends = []\n",
    "        for metric_name in current_metrics:\n",
    "            values = [record[\"metrics\"].get(metric_name, 0) for record in recent_performance]\n",
    "            if len(values) > 1:\n",
    "                trend = \"increasing\" if values[-1] > values[0] else \"decreasing\"\n",
    "                trends.append(f\"{metric_name}:{trend}\")\n",
    "        \n",
    "        return \", \".join(trends)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Example Usage and Demonstrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_langchain_agents():\n",
    "    \"\"\"Demonstrate LangChain agent capabilities\"\"\"\n",
    "    \n",
    "    print(\"=== LangChain Agent Framework Demo ===\")\n",
    "    \n",
    "    # Initialize framework\n",
    "    langchain_framework = LangChainAgentFramework(llm, tools)\n",
    "    \n",
    "    # Create various agents\n",
    "    research_agent = langchain_framework.create_react_agent(\n",
    "        \"researcher\",\n",
    "        system_prompt=\"\"\"You are a research specialist with access to search tools.\n",
    "        Conduct thorough research and provide comprehensive summaries.\n",
    "        Always verify information and cite sources.\"\"\"\n",
    "    )\n",
    "    \n",
    "    conversational_agent = langchain_framework.create_conversational_agent(\n",
    "        \"chatbot\",\n",
    "        system_prompt=\"\"\"You are a friendly conversational AI assistant.\n",
    "        Be engaging, helpful, and provide accurate information.\n",
    "        Maintain context from previous messages.\"\"\"\n",
    "    )\n",
    "    \n",
    "    planning_agent = langchain_framework.create_planning_agent(\n",
    "        \"planner\",\n",
    "        system_prompt=\"\"\"You are an expert planning assistant.\n",
    "        Break down complex tasks into clear, manageable steps.\n",
    "        Consider dependencies and provide logical sequences.\"\"\"\n",
    "    )\n",
    "    \n",
    "    print(\"\\nAvailable agents:\", langchain_framework.list_agents())\n",
    "    \n",
    "    # Demonstrate agent capabilities\n",
    "    print(\"\\n=== Testing Research Agent ===\")\n",
    "    research_result = langchain_framework.run_agent(\n",
    "        \"researcher\",\n",
    "        \"Search for information about artificial intelligence trends in 2024\"\n",
    "    )\n",
    "    print(f\"Research result: {research_result[:200]}...\")\n",
    "    \n",
    "    print(\"\\n=== Testing Conversational Agent ===\")\n",
    "    conv_result = langchain_framework.run_agent(\n",
    "        \"chatbot\",\n",
    "        \"Hello! I'm learning about AI agents. Can you tell me what makes them special?\"\n",
    "    )\n",
    "    print(f\"Conversation result: {conv_result[:200]}...\")\n",
    "    \n",
    "    print(\"\\n=== Testing Planning Agent ===\")\n",
    "    plan_result = langchain_framework.run_agent(\n",
    "        \"planner\",\n",
    "        \"Plan the development of a simple AI chatbot application\"\n",
    "    )\n",
    "    print(f\"Planning result: {plan_result[:300]}...\")\n",
    "    \n",
    "    return langchain_framework\n",
    "\n",
    "def demonstrate_autogen_agents():\n",
    "    \"\"\"Demonstrate AutoGen agent capabilities\"\"\"\n",
    "    \n",
    "    print(\"\\n=== AutoGen Agent Framework Demo ===\")\n",
    "    \n",
    "    try:\n",
    "        # Initialize framework\n",
    "        autogen_framework = setup_autogen_example()\n",
    "        \n",
    "        print(\"\\nAvailable agents:\", autogen_framework.list_agents())\n",
    "        print(\"Available group chats:\", autogen_framework.list_group_chats())\n",
    "        \n",
    "        # Demonstrate group chat (this would require actual LLM calls)\n",
    "        print(\"\\n=== Group Chat Demonstration ===\")\n",
    "        print(\"Note: This would require actual LLM API calls to execute\")\n",
    "        print(\"The group chat would include: planner, coder, and reviewer agents\")\n",
    "        print(\"They would collaborate on a software development task\")\n",
    "        \n",
    "        return autogen_framework\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"AutoGen demonstration skipped due to import issue: {e}\")\n",
    "        return None\n",
    "\n",
    "def demonstrate_multi_agent_system():\n",
    "    \"\"\"Demonstrate multi-agent system with memory and learning\"\"\"\n",
    "    \n",
    "    print(\"\\n=== Multi-Agent System Demo ===\")\n",
    "    \n",
    "    # Initialize frameworks\n",
    "    langchain_framework = LangChainAgentFramework(llm, tools)\n",
    "    autogen_framework = setup_autogen_example()\n",
    "    \n",
    "    # Create multi-agent system\n",
    "    multi_agent_system = MultiAgentSystem(langchain_framework, autogen_framework)\n",
    "    \n",
    "    # Create specialized agents\n",
    "    agents = multi_agent_system.create_specialized_agents()\n",
    "    \n",
    "    # Create memory system\n",
    "    memory_system = AgentMemorySystem()\n",
    "    \n",
    "    # Create learning agents\n",
    "    learning_agents = {}\n",
    "    for agent_name, agent in agents.items():\n",
    "        learning_agents[agent_name] = LearningAgent(agent_name, memory_system)\n",
    "    \n",
    "    print(f\"\\nCreated {len(agents)} specialized agents:\")\n",
    "    for agent_name in agents.keys():\n",
    "        print(f\"  - {agent_name}\")\n",
    "    \n",
    "    # Create workflow\n",
    "    workflow_config = {\n",
    "        \"steps\": [\n",
    "            {\n",
    "                \"name\": \"research_step\",\n",
    "                \"agent\": \"researcher\",\n",
    "                \"task\": \"Research the topic: {topic}\",\n",
    "                \"output_key\": \"research_results\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"analysis_step\",\n",
    "                \"agent\": \"analyst\",\n",
    "                \"task\": \"Analyze the research results: {research_results}\",\n",
    "                \"output_key\": \"analysis_results\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"strategy_step\",\n",
    "                \"agent\": \"strategist\",\n",
    "                \"task\": \"Develop strategy based on: {analysis_results}\",\n",
    "                \"output_key\": \"strategy\"\n",
    "            }\n",
    "        ],\n",
    "        \"output_format\": \"detailed\"\n",
    "    }\n",
    "    \n",
    "    workflow = multi_agent_system.create_agent_workflow(\n",
    "        \"research_workflow\",\n",
    "        agents,\n",
    "        workflow_config\n",
    "    )\n",
    "    \n",
    "    print(\"\\nCreated workflow: research_workflow\")\n",
    "    \n",
    "    # Simulate workflow execution\n",
    "    input_data = {\"topic\": \"AI agent frameworks and their applications\"}\n",
    "    \n",
    "    print(f\"\\nSimulating workflow execution with input: {input_data}\")\n",
    "    print(\"Note: This would require actual LLM calls to execute\")\n",
    "    \n",
    "    # Demonstrate memory system\n",
    "    print(\"\\n=== Memory System Demo ===\")\n",
    "    \n",
    "    # Add some test memories\n",
    "    memory_system.add_semantic_memory(\n",
    "        \"agent_frameworks\",\n",
    "        {\n",
    "            \"description\": \"LangChain and AutoGen are popular AI agent frameworks\",\n",
    "            \"langchain_features\": [\"tools\", \"chains\", \"agents\"],\n",
    "            \"autogen_features\": [\"multi-agent\", \"conversation\", \"coding\"]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    memory_system.add_episodic_memory({\n",
    "        \"event\": \"framework_comparison\",\n",
    "        \"details\": \"Compared LangChain and AutoGen capabilities\",\n",
    "        \"conclusion\": \"Both have strengths for different use cases\"\n",
    "    })\n",
    "    \n",
    "    # Test memory retrieval\n",
    "    relevant_memories = memory_system.retrieve_relevant_memories(\n",
    "        \"What are the features of AI agent frameworks?\",\n",
    "        limit=2\n",
    "    )\n",
    "    \n",
    "    print(f\"Retrieved {len(relevant_memories)} relevant memories\")\n",
    "    for i, memory in enumerate(relevant_memories):\n",
    "        print(f\"Memory {i+1}: {memory.get('description', memory.get('event', 'Unknown'))}\")\n",
    "    \n",
    "    # Show memory stats\n",
    "    stats = memory_system.get_memory_stats()\n",
    "    print(f\"\\nMemory System Stats: {stats}\")\n",
    "    \n",
    "    return multi_agent_system, memory_system\n",
    "\n",
    "def main_demonstration():\n",
    "    \"\"\"Main demonstration function\"\"\"\n",
    "    \n",
    "    print(\"ð AI Agent Frameworks Comprehensive Demonstration\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Demonstrate LangChain\n",
    "    langchain_framework = demonstrate_langchain_agents()\n",
    "    \n",
    "    # Demonstrate AutoGen\n",
    "    autogen_framework = demonstrate_autogen_agents()\n",
    "    \n",
    "    # Demonstrate multi-agent system\n",
    "    multi_agent_system, memory_system = demonstrate_multi_agent_system()\n",
    "    \n",
    "    print(\"\\n=== Summary ===\")\n",
    "    print(\"â LangChain agents with tool usage and memory\")\n",
    "    print(\"â AutoGen multi-agent conversation framework\")\n",
    "    print(\"â Advanced multi-agent workflows and coordination\")\n",
    "    print(\"â Memory systems with semantic and episodic storage\")\n",
    "    print(\"â Learning agents that adapt from interactions\")\n",
    "    \n",
    "    print(\"\\nð¯ Key Capabilities Demonstrated:\")\n",
    "    print(\"  â¢ Tool-using agents with ReAct paradigm\")\n",
    "    print(\"  â¢ Conversational agents with memory\")\n",
    "    print(\"  â¢ Planning and task decomposition\")\n",
    "    print(\"  â¢ Multi-agent collaboration\")\n",
    "    print(\"  â¢ Workflow orchestration\")\n",
    "    print(\"  â¢ Memory and learning systems\")\n",
    "    print(\"  â¢ Agent coordination and communication\")\n",
    "    \n",
    "    return {\n",
    "        \"langchain_framework\": langchain_framework,\n",
    "        \"autogen_framework\": autogen_framework,\n",
    "        \"multi_agent_system\": multi_agent_system,\n",
    "        \"memory_system\": memory_system\n",
    "    }\n",
    "\n",
    "# Run the demonstration\n",
    "if __name__ == \"__main__\":\n",
    "    frameworks = main_demonstration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Performance Monitoring and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentPerformanceMonitor:\n",
    "    \"\"\"Monitor and evaluate agent performance\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.metrics_history = []\n",
    "        self.agent_stats = {}\n",
    "        self.workflow_stats = {}\n",
    "    \n",
    "    def record_agent_execution(self, agent_name: str, execution_data: Dict):\n",
    "        \"\"\"Record agent execution metrics\"\"\"\n",
    "        \n",
    "        execution_record = {\n",
    "            \"timestamp\": datetime.now(),\n",
    "            \"agent_name\": agent_name,\n",
    "            \"execution_time\": execution_data.get(\"execution_time\", 0),\n",
    "            \"success\": execution_data.get(\"success\", False),\n",
    "            \"tokens_used\": execution_data.get(\"tokens_used\", 0),\n",
    "            \"tool_calls\": execution_data.get(\"tool_calls\", 0),\n",
    "            \"error_rate\": execution_data.get(\"error_rate\", 0),\n",
    "            \"user_satisfaction\": execution_data.get(\"user_satisfaction\", 0),\n",
    "        }\n",
    "        \n",
    "        self.metrics_history.append(execution_record)\n",
    "        \n",
    "        # Update agent statistics\n",
    "        if agent_name not in self.agent_stats:\n",
    "            self.agent_stats[agent_name] = {\n",
    "                \"total_executions\": 0,\n",
    "                \"total_time\": 0,\n",
    "                \"successful_executions\": 0,\n",
    "                \"total_tokens\": 0,\n",
    "                \"total_tool_calls\": 0,\n",
    "            }\n",
    "        \n",
    "        stats = self.agent_stats[agent_name]\n",
    "        stats[\"total_executions\"] += 1\n",
    "        stats[\"total_time\"] += execution_record[\"execution_time\"]\n",
    "        if execution_record[\"success\"]:\n",
    "            stats[\"successful_executions\"] += 1\n",
    "        stats[\"total_tokens\"] += execution_record[\"tokens_used\"]\n",
    "        stats[\"total_tool_calls\"] += execution_record[\"tool_calls\"]\n",
    "    \n",
    "    def record_workflow_execution(self, workflow_name: str, workflow_data: Dict):\n",
    "        \"\"\"Record workflow execution metrics\"\"\"\n",
    "        \n",
    "        workflow_record = {\n",
    "            \"timestamp\": datetime.now(),\n",
    "            \"workflow_name\": workflow_name,\n",
    "            \"total_time\": workflow_data.get(\"total_time\", 0),\n",
    "            \"steps_completed\": workflow_data.get(\"steps_completed\", 0),\n",
    "            \"steps_total\": workflow_data.get(\"steps_total\", 0),\n",
    "            \"success\": workflow_data.get(\"success\", False),\n",
    "            \"agents_involved\": workflow_data.get(\"agents_involved\", []),\n",
    "        }\n",
    "        \n",
    "        self.metrics_history.append(workflow_record)\n",
    "        \n",
    "        # Update workflow statistics\n",
    "        if workflow_name not in self.workflow_stats:\n",
    "            self.workflow_stats[workflow_name] = {\n",
    "                \"total_executions\": 0,\n",
    "                \"successful_executions\": 0,\n",
    "                \"average_time\": 0,\n",
    "                \"average_completion_rate\": 0,\n",
    "            }\n",
    "        \n",
    "        stats = self.workflow_stats[workflow_name]\n",
    "        stats[\"total_executions\"] += 1\n",
    "        if workflow_record[\"success\"]:\n",
    "            stats[\"successful_executions\"] += 1\n",
    "        \n",
    "        # Update averages\n",
    "        executions = stats[\"total_executions\"]\n",
    "        stats[\"average_time\"] = (stats[\"average_time\"] * (executions - 1) + workflow_record[\"total_time\"]) / executions\n",
    "        \n",
    "        completion_rate = workflow_record[\"steps_completed\"] / max(workflow_record[\"steps_total\"], 1)\n",
    "        stats[\"average_completion_rate\"] = (stats[\"average_completion_rate\"] * (executions - 1) + completion_rate) / executions\n",
    "    \n",
    "    def get_agent_performance_report(self, agent_name: str) -> Dict:\n",
    "        \"\"\"Generate performance report for specific agent\"\"\"\n",
    "        \n",
    "        if agent_name not in self.agent_stats:\n",
    "            return {\"error\": f\"No data available for agent '{agent_name}'\"}\n",
    "        \n",
    "        stats = self.agent_stats[agent_name]\n",
    "        \n",
    "        if stats[\"total_executions\"] == 0:\n",
    "            return {\"error\": \"No executions recorded for this agent\"}\n",
    "        \n",
    "        report = {\n",
    "            \"agent_name\": agent_name,\n",
    "            \"total_executions\": stats[\"total_executions\"],\n",
    "            \"success_rate\": stats[\"successful_executions\"] / stats[\"total_executions\"],\n",
    "            \"average_execution_time\": stats[\"total_time\"] / stats[\"total_executions\"],\n",
    "            \"average_tokens_per_execution\": stats[\"total_tokens\"] / stats[\"total_executions\"],\n",
    "            \"average_tool_calls\": stats[\"total_tool_calls\"] / stats[\"total_executions\"],\n",
    "            \"efficiency_score\": self._calculate_efficiency_score(agent_name),\n",
    "        }\n",
    "        \n",
    "        return report\n",
    "    \n",
    "    def get_workflow_performance_report(self, workflow_name: str) -> Dict:\n",
    "        \"\"\"Generate performance report for specific workflow\"\"\"\n",
    "        \n",
    "        if workflow_name not in self.workflow_stats:\n",
    "            return {\"error\": f\"No data available for workflow '{workflow_name}'\"}\n",
    "        \n",
    "        stats = self.workflow_stats[workflow_name]\n",
    "        \n",
    "        report = {\n",
    "            \"workflow_name\": workflow_name,\n",
    "            \"total_executions\": stats[\"total_executions\"],\n",
    "            \"success_rate\": stats[\"successful_executions\"] / stats[\"total_executions\"],\n",
    "            \"average_execution_time\": stats[\"average_time\"],\n",
    "            \"average_completion_rate\": stats[\"average_completion_rate\"],\n",
    "            \"reliability_score\": self._calculate_reliability_score(workflow_name),\n",
    "        }\n",
    "        \n",
    "        return report\n",
    "    \n",
    "    def get_system_overview(self) -> Dict:\n",
    "        \"\"\"Get system-wide performance overview\"\"\"\n",
    "        \n",
    "        total_executions = len(self.metrics_history)\n",
    "        recent_executions = [record for record in self.metrics_history \n",
    "                            if (datetime.now() - record[\"timestamp\"]).days < 7]\n",
    "        \n",
    "        overview = {\n",
    "            \"total_executions\": total_executions,\n",
    "            \"recent_executions_7d\": len(recent_executions),\n",
    "            \"agents_monitored\": len(self.agent_stats),\n",
    "            \"workflows_monitored\": len(self.workflow_stats),\n",
    "            \"overall_success_rate\": self._calculate_overall_success_rate(),\n",
    "            \"average_execution_time\": self._calculate_average_execution_time(),\n",
    "            \"system_health_score\": self._calculate_system_health_score(),\n",
    "        }\n",
    "        \n",
    "        return overview\n",
    "    \n",
    "    def _calculate_efficiency_score(self, agent_name: str) -> float:\n",
    "        \"\"\"Calculate efficiency score for agent\"\"\"\n",
    "        if agent_name not in self.agent_stats:\n",
    "            return 0.0\n",
    "        \n",
    "        stats = self.agent_stats[agent_name]\n",
    "        \n",
    "        if stats[\"total_executions\"] == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        # Efficiency = success_rate / (execution_time + 1) * (1 + tool_calls / executions)\n",
    "        success_rate = stats[\"successful_executions\"] / stats[\"total_executions\"]\n",
    "        avg_time = stats[\"total_time\"] / stats[\"total_executions\"]\n",
    "        avg_tool_calls = stats[\"total_tool_calls\"] / stats[\"total_executions\"]\n",
    "        \n",
    "        efficiency = success_rate / (avg_time + 1) * (1 + avg_tool_calls)\n",
    "        return min(efficiency * 100, 100)  # Scale to 0-100\n",
    "    \n",
    "    def _calculate_reliability_score(self, workflow_name: str) -> float:\n",
    "        \"\"\"Calculate reliability score for workflow\"\"\"\n",
    "        if workflow_name not in self.workflow_stats:\n",
    "            return 0.0\n",
    "        \n",
    "        stats = self.workflow_stats[workflow_name]\n",
    "        \n",
    "        # Reliability = success_rate * completion_rate\n",
    "        success_rate = stats[\"successful_executions\"] / stats[\"total_executions\"]\n",
    "        completion_rate = stats[\"average_completion_rate\"]\n",
    "        \n",
    "        return (success_rate * completion_rate) * 100\n",
    "    \n",
    "    def _calculate_overall_success_rate(self) -> float:\n",
    "        \"\"\"Calculate overall system success rate\"\"\"\n",
    "        if not self.metrics_history:\n",
    "            return 0.0\n",
    "        \n",
    "        successful = sum(1 for record in self.metrics_history if record.get(\"success\", False))\n",
    "        return (successful / len(self.metrics_history)) * 100\n",
    "    \n",
    "    def _calculate_average_execution_time(self) -> float:\n",
    "        \"\"\"Calculate average execution time\"\"\"\n",
    "        if not self.metrics_history:\n",
    "            return 0.0\n",
    "        \n",
    "        execution_times = [record.get(\"execution_time\", 0) for record in self.metrics_history]\n",
    "        return sum(execution_times) / len(execution_times)\n",
    "    \n",
    "    def _calculate_system_health_score(self) -> float:\n",
    "        \"\"\"Calculate overall system health score\"\"\"\n",
    "        # Health = (success_rate * 0.4) + (efficiency * 0.3) + (reliability * 0.3)\n",
    "        success_rate = self._calculate_overall_success_rate()\n",
    "        \n",
    "        # Calculate average efficiency\n",
    "        if self.agent_stats:\n",
    "            avg_efficiency = sum(self._calculate_efficiency_score(agent) for agent in self.agent_stats) / len(self.agent_stats)\n",
    "        else:\n",
    "            avg_efficiency = 0\n",
    "        \n",
    "        # Calculate average reliability\n",
    "        if self.workflow_stats:\n",
    "            avg_reliability = sum(self._calculate_reliability_score(workflow) for workflow in self.workflow_stats) / len(self.workflow_stats)\n",
    "        else:\n",
    "            avg_reliability = 0\n",
    "        \n",
    "        health_score = (success_rate * 0.4) + (avg_efficiency * 0.3) + (avg_reliability * 0.3)\n",
    "        return min(health_score, 100)\n",
    "    \n",
    "    def export_metrics(self, filename: str = \"agent_metrics.json\"):\n",
    "        \"\"\"Export metrics to JSON file\"\"\"\n",
    "        export_data = {\n",
    "            \"export_timestamp\": datetime.now().isoformat(),\n",
    "            \"agent_stats\": self.agent_stats,\n",
    "            \"workflow_stats\": self.workflow_stats,\n",
    "            \"system_overview\": self.get_system_overview(),\n",
    "            \"recent_metrics\": self.metrics_history[-100:]  # Last 100 records\n",
    "        }\n",
    "        \n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(export_data, f, indent=2, default=str)\n",
    "        \n",
    "        print(f\"Metrics exported to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Best Practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Capabilities Demonstrated:\n",
    "\n",
    "1. **LangChain Agents**:\n",
    "   - ReAct agents with tool usage\n",
    "   - Conversational agents with memory\n",
    "   - Planning and task decomposition\n",
    "   - Multi-tool coordination\n",
    "   - Custom tool creation\n",
    "\n",
    "2. **AutoGen Framework**:\n",
    "   - Multi-agent conversation systems\n",
    "   - Group chat management\n",
    "   - Specialized agent roles\n",
    "   - Asynchronous agent communication\n",
    "\n",
    "3. **Multi-Agent Systems**:\n",
    "   - Workflow orchestration\n",
    "   - Agent coordination\n",
    "   - Dependency management\n",
    "   - Parallel execution\n",
    "\n",
    "4. **Memory and Learning**:\n",
    "   - Short-term and long-term memory\n",
    "   - Semantic and episodic memory\n",
    "   - Memory retrieval and indexing\n",
    "   - Learning from interactions\n",
    "   - Behavior adaptation\n",
    "\n",
    "5. **Performance Monitoring**:\n",
    "   - Agent performance metrics\n",
    "   - Workflow execution tracking\n",
    "   - Efficiency and reliability scoring\n",
    "   - System health monitoring\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "1. **Agent Design**:\n",
    "   - Define clear roles and responsibilities\n",
    "   - Use appropriate system prompts\n",
    "   - Implement proper error handling\n",
    "   - Include memory for context retention\n",
    "\n",
    "2. **Tool Usage**:\n",
    "   - Provide clear tool descriptions\n",
    "   - Implement proper error handling\n",
    "   - Use tools judiciously\n",
    "   - Validate tool inputs and outputs\n",
    "\n",
    "3. **Multi-Agent Coordination**:\n",
    "   - Define clear communication protocols\n",
    "   - Manage agent dependencies\n",
    "   - Implement proper workflow orchestration\n",
    "   - Handle conflicts and failures gracefully\n",
    "\n",
    "4. **Memory Management**:\n",
    "   - Balance memory usage and performance\n",
    "   - Implement efficient retrieval mechanisms\n",
    "   - Use appropriate memory consolidation strategies\n",
    "   - Respect privacy and data retention policies\n",
    "\n",
    "5. **Performance Optimization**:\n",
    "   - Monitor key performance metrics\n",
    "   - Optimize agent response times\n",
    "   - Balance between capability and efficiency\n",
    "   - Implement proper caching strategies\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Implement actual LLM API integration\n",
    "- Add more sophisticated tool implementations\n",
    "- Implement agent learning and adaptation algorithms\n",
    "- Add visualization for agent workflows\n",
    "- Implement agent security and access control\n",
    "- Add agent versioning and deployment management"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}