{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification with PyTorch\n",
    "\n",
    "This notebook provides a comprehensive guide to image classification using PyTorch, covering from basic CNNs to advanced architectures and techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \"\"\"Custom dataset class for image classification\"\"\"\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.classes = sorted(os.listdir(data_dir))\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "        \n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for class_name in self.classes:\n",
    "            class_dir = os.path.join(data_dir, class_name)\n",
    "            if os.path.isdir(class_dir):\n",
    "                for img_name in os.listdir(class_dir):\n",
    "                    if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                        self.images.append(os.path.join(class_dir, img_name))\n",
    "                        self.labels.append(self.class_to_idx[class_name])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "def get_data_transforms(image_size=224):\n",
    "    \"\"\"Define data transformations for training and validation\"\"\"\n",
    "    \n",
    "    # Training transforms with augmentation\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(image_size),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Validation transforms\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    return train_transform, val_transform\n",
    "\n",
    "def load_datasets(data_dir, batch_size=32, image_size=224):\n",
    "    \"\"\"Load and prepare datasets\"\"\"\n",
    "    \n",
    "    # Get transforms\n",
    "    train_transform, val_transform = get_data_transforms(image_size)\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = CustomDataset(\n",
    "        os.path.join(data_dir, 'train'),\n",
    "        transform=train_transform\n",
    "    )\n",
    "    \n",
    "    val_dataset = CustomDataset(\n",
    "        os.path.join(data_dir, 'val'),\n",
    "        transform=val_transform\n",
    "    )\n",
    "    \n",
    "    test_dataset = CustomDataset(\n",
    "        os.path.join(data_dir, 'test'),\n",
    "        transform=val_transform\n",
    "    )\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, train_dataset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicCNN(nn.Module):\n",
    "    \"\"\"Basic CNN architecture\"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(BasicCNN, self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            # Conv Block 1\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Conv Block 2\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Conv Block 3\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Conv Block 4\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"Residual block for ResNet\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = self.shortcut(x)\n",
    "        \n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        \n",
    "        out += residual\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class CustomResNet(nn.Module):\n",
    "    \"\"\"Custom ResNet implementation\"\"\"\n",
    "    def __init__(self, block, layers, num_classes=10):\n",
    "        super(CustomResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        \n",
    "    def _make_layer(self, block, channels, blocks, stride=1):\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, channels, stride))\n",
    "        self.in_channels = channels * block.expansion\n",
    "        \n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_channels, channels))\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def resnet18_custom(num_classes=10):\n",
    "    \"\"\"Custom ResNet-18\"\"\"\n",
    "    class BasicBlock(nn.Module):\n",
    "        expansion = 1\n",
    "        def __init__(self, in_channels, out_channels, stride=1):\n",
    "            super(BasicBlock, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "            self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "            self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "            self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "            \n",
    "            self.shortcut = nn.Sequential()\n",
    "            if stride != 1 or in_channels != out_channels:\n",
    "                self.shortcut = nn.Sequential(\n",
    "                    nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                    nn.BatchNorm2d(out_channels)\n",
    "                )\n",
    "        \n",
    "        def forward(self, x):\n",
    "            residual = self.shortcut(x)\n",
    "            \n",
    "            out = F.relu(self.bn1(self.conv1(x)))\n",
    "            out = self.bn2(self.conv2(out))\n",
    "            \n",
    "            out += residual\n",
    "            out = F.relu(out)\n",
    "            \n",
    "            return out\n",
    "    \n",
    "    return CustomResNet(BasicBlock, [2, 2, 2, 2], num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    \"\"\"Training class for image classification\"\"\"\n",
    "    def __init__(self, model, train_loader, val_loader, test_loader, \n",
    "                 device, classes, save_dir='checkpoints'):\n",
    "        self.model = model.to(device)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.device = device\n",
    "        self.classes = classes\n",
    "        self.save_dir = save_dir\n",
    "        \n",
    "        # Create save directory\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        # Initialize training history\n",
    "        self.history = {\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': [],\n",
    "            'lr': []\n",
    "            'epoch_time': []\n",
    "        }\n",
    "        \n",
    "        # Best model tracking\n",
    "        self.best_val_acc = 0.0\n",
    "        self.best_model_state = None\n",
    "        \n",
    "    def train_epoch(self, optimizer, criterion):\n",
    "        \"\"\"Train for one epoch\"\"\"\n",
    "        self.model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        progress_bar = tqdm(self.train_loader, desc='Training')\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(progress_bar):\n",
    "            data, target = data.to(self.device), target.to(self.device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = self.model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({\n",
    "                'Loss': f'{running_loss/(batch_idx+1):.4f}',\n",
    "                'Acc': f'{100.*correct/total:.2f}%'\n",
    "            })\n",
    "        \n",
    "        train_loss = running_loss / len(self.train_loader)\n",
    "        train_acc = 100. * correct / total\n",
    "        \n",
    "        return train_loss, train_acc\n",
    "    \n",
    "    def validate(self, criterion):\n",
    "        \"\"\"Validate the model\"\"\"\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in tqdm(self.val_loader, desc='Validation'):\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                output = self.model(data)\n",
    "                loss = criterion(output, target)\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                _, predicted = output.max(1)\n",
    "                total += target.size(0)\n",
    "                correct += predicted.eq(target).sum().item()\n",
    "                \n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_targets.extend(target.cpu().numpy())\n",
    "        \n",
    "        val_loss = running_loss / len(self.val_loader)\n",
    "        val_acc = 100. * correct / total\n",
    "        \n",
    "        return val_loss, val_acc, all_preds, all_targets\n",
    "    \n",
    "    def train(self, num_epochs, optimizer, criterion, scheduler=None,\n",
    "               early_stopping_patience=10, save_best_only=True):\n",
    "        \"\"\"Main training loop\"\"\"\n",
    "        print(f\"Starting training for {num_epochs} epochs...\")\n",
    "        \n",
    "        # Early stopping\n",
    "        early_stopping_counter = 0\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Training\n",
    "            train_loss, train_acc = self.train_epoch(optimizer, criterion)\n",
    "            \n",
    "            # Validation\n",
    "            val_loss, val_acc, val_preds, val_targets = self.validate(criterion)\n",
    "            \n",
    "            # Update learning rate\n",
    "            if scheduler:\n",
    "                if isinstance(scheduler, ReduceLROnPlateau):\n",
    "                    scheduler.step(val_loss)\n",
    "                else:\n",
    "                    scheduler.step()\n",
    "            \n",
    "            # Record metrics\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            epoch_time = time.time() - start_time\n",
    "            \n",
    "            self.history['train_loss'].append(train_loss)\n",
    "            self.history['train_acc'].append(train_acc)\n",
    "            self.history['val_loss'].append(val_loss)\n",
    "            self.history['val_acc'].append(val_acc)\n",
    "            self.history['lr'].append(current_lr)\n",
    "            self.history['epoch_time'].append(epoch_time)\n",
    "            \n",
    "            # Print epoch results\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "            print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "            print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "            print(f'LR: {current_lr:.6f}, Time: {epoch_time:.2f}s')\n",
    "            print('-' * 50)\n",
    "            \n",
    "            # Save best model\n",
    "            if val_acc > self.best_val_acc:\n",
    "                self.best_val_acc = val_acc\n",
    "                self.best_model_state = self.model.state_dict().copy()\n",
    "                \n",
    "                if save_best_only:\n",
    "                    self.save_checkpoint(epoch, optimizer, scheduler, is_best=True)\n",
    "                \n",
    "                early_stopping_counter = 0\n",
    "            else:\n",
    "                early_stopping_counter += 1\n",
    "            \n",
    "            # Early stopping check\n",
    "            if early_stopping_counter >= early_stopping_patience:\n",
    "                print(f'Early stopping triggered after {epoch+1} epochs')\n",
    "                break\n",
    "            \n",
    "            # Save checkpoint periodically\n",
    "            if (epoch + 1) % 10 == 0 and not save_best_only:\n",
    "                self.save_checkpoint(epoch, optimizer, scheduler)\n",
    "        \n",
    "        # Load best model\n",
    "        if self.best_model_state is not None:\n",
    "            self.model.load_state_dict(self.best_model_state)\n",
    "            print(f'Loaded best model with validation accuracy: {self.best_val_acc:.2f}%')\n",
    "    \n",
    "    def save_checkpoint(self, epoch, optimizer, scheduler, is_best=False):\n",
    "        \"\"\"Save model checkpoint\"\"\"\n",
    "        checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': self.model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'scheduler': scheduler.state_dict() if scheduler else None,\n",
    "            'best_val_acc': self.best_val_acc,\n",
    "            'history': self.history\n",
    "        }\n",
    "        \n",
    "        if is_best:\n",
    "            filename = os.path.join(self.save_dir, 'best_model.pth')\n",
    "        else:\n",
    "            filename = os.path.join(self.save_dir, f'checkpoint_epoch_{epoch+1}.pth')\n",
    "        \n",
    "        torch.save(checkpoint, filename)\n",
    "        print(f'Saved checkpoint: {filename}')\n",
    "    \n",
    "    def load_checkpoint(self, checkpoint_path):\n",
    "        \"\"\"Load model checkpoint\"\"\"\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "        \n",
    "        self.model.load_state_dict(checkpoint['state_dict'])\n",
    "        \n",
    "        if 'history' in checkpoint:\n",
    "            self.history = checkpoint['history']\n",
    "        \n",
    "        if 'best_val_acc' in checkpoint:\n",
    "            self.best_val_acc = checkpoint['best_val_acc']\n",
    "            \n",
    "        print(f'Loaded checkpoint from epoch {checkpoint[\"epoch\"]}')\n",
    "        print(f'Best validation accuracy: {self.best_val_acc:.2f}%')\n",
    "        \n",
    "        return checkpoint['epoch'], checkpoint.get('history', self.history)\n",
    "    \n",
    "    def test(self):\n",
    "        \"\"\"Test the model\"\"\"\n",
    "        self.model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "        all_probs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in tqdm(self.test_loader, desc='Testing'):\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                output = self.model(data)\n",
    "                \n",
    "                probs = F.softmax(output, dim=1)\n",
    "                _, predicted = output.max(1)\n",
    "                \n",
    "                total += target.size(0)\n",
    "                correct += predicted.eq(target).sum().item()\n",
    "                \n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_targets.extend(target.cpu().numpy())\n",
    "                all_probs.extend(probs.cpu().numpy())\n",
    "        \n",
    "        test_acc = 100. * correct / total\n",
    "        \n",
    "        print(f'Test Accuracy: {test_acc:.2f}%')\n",
    "        \n",
    "        return test_acc, all_preds, all_targets, all_probs\n",
    "    \n",
    "    def evaluate_predictions(self, y_true, y_pred, y_prob=None):\n",
    "        \"\"\"Evaluate predictions with comprehensive metrics\"\"\"\n",
    "        # Classification report\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_true, y_pred, target_names=self.classes))\n",
    "        \n",
    "        # Confusion matrix\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                   xticklabels=self.classes, yticklabels=self.classes)\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Transfer Learning with Pre-trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pretrained_model(model_name, num_classes, pretrained=True):\n",
    "    \"\"\"Create a pre-trained model with custom classifier\"\"\"\n",
    "    \n",
    "    if model_name == 'resnet18':\n",
    "        model = models.resnet18(pretrained=pretrained)\n",
    "        num_features = model.fc.in_features\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    elif model_name == 'resnet50':\n",
    "        model = models.resnet50(pretrained=pretrained)\n",
    "        num_features = model.fc.in_features\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    elif model_name == 'efficientnet_b0':\n",
    "        model = models.efficientnet_b0(pretrained=pretrained)\n",
    "        num_features = model.classifier[1].in_features\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(num_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    elif model_name == 'vgg16':\n",
    "        model = models.vgg16(pretrained=pretrained)\n",
    "        num_features = model.classifier[6].in_features\n",
    "        model.classifier[6] = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    elif model_name == 'densenet121':\n",
    "        model = models.densenet121(pretrained=pretrained)\n",
    "        num_features = model.classifier.in_features\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    elif model_name == 'mobilenet_v2':\n",
    "        model = models.mobilenet_v2(pretrained=pretrained)\n",
    "        num_features = model.classifier[1].in_features\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(num_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model: {model_name}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_model_summary(model, input_size=(3, 224, 224)):\n",
    "    \"\"\"Get model summary\"\"\"\n",
    "    from torchsummary import summary\n",
    "    summary(model, input_size)\n",
    "\n",
    "def count_parameters(model):\n",
    "    \"\"\"Count number of trainable parameters\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Advanced Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixupAugmentation:\n",
    "    \"\"\"Mixup augmentation for training\"\"\"\n",
    "    def __init__(self, alpha=1.0):\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def __call__(self, x, y):\n",
    "        \"\"\"Apply mixup to batch\"\"\"\n        "        if self.alpha > 0:\n",
    "            lam = np.random.beta(self.alpha, self.alpha)\n",
    "        else:\n",
    "            lam = 1\n",
    "        \n",
    "        batch_size = x.size()[0]\n",
    "        index = torch.randperm(batch_size).to(x.device)\n",
    "        \n",
    "        mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "        y_a, y_b = y, y[index]\n",
    "        \n",
    "        return mixed_x, y_a, y_b, lam\n",
    "\n",
    "class CutMixAugmentation:\n",
    "    \"\"\"CutMix augmentation for training\"\"\"\n    "    def __init__(self, alpha=1.0):\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def __call__(self, x, y):\n",
    "        \"\"\"Apply CutMix to batch\"\"\"\n    "        if self.alpha > 0:\n",
    "            lam = np.random.beta(self.alpha, self.alpha)\n",
    "        else:\n",
    "            lam = 1\n",
    "        \n",
    "        batch_size = x.size()[0]\n",
    "        index = torch.randperm(batch_size).to(x.device)\n",
    "        \n",
    "        bbx1, bby1, bbx2, bby2 = self.rand_bbox(x.size(), lam)\n",
    "        \n",
    "        x[:, :, bbx1:bbx2, bby1:bby2] = x[index, :, bbx1:bbx2, bby1:bby2]\n",
    "        \n",
    "        # Adjust lambda to exactly match pixel ratio\n",
    "        lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (x.size()[-1] * x.size()[-2]))\n",
    "        \n",
    "        y_a, y_b = y, y[index]\n",
    "        \n",
    "        return x, y_a, y_b, lam\n",
    "    \n",
    "    def rand_bbox(self, size, lam):\n",
    "        \"\"\"Generate random bounding box\"\"\"\n    "        W = size[2]\n",
    "        H = size[3]\n",
    "        cut_rat = np.sqrt(1. - lam)\n",
    "        cut_w = np.int(W * cut_rat)\n",
    "        cut_h = np.int(H * cut_rat)\n",
    "        \n",
    "        # Uniform\n",
    "        cx = np.random.randint(W)\n",
    "        cy = np.random.randint(H)\n",
    "        \n",
    "        bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "        bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "        bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "        bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "        \n",
    "        return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    \"\"\"Label smoothing loss\"\"\"\n    "    def __init__(self, num_classes, smoothing=0.1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.smoothing = smoothing\n",
    "        self.confidence = 1.0 - smoothing\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=-1)\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.num_classes - 1))\n",
    "            true_dist.scatter_(1, target.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=-1))\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Focal Loss for handling class imbalance\"\"\"\n    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "def get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps, num_cycles=0.5):\n",
    "    \"\"\"Create cosine schedule with warmup\"\"\"\n    "    def lr_lambda(current_step):\n",
    "        if current_step < num_warmup_steps:\n",
    "            return float(current_step) / float(max(1, num_warmup_steps))\n",
    "        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress)))\n",
    "    \n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualization and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training history\"\"\"\n    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Loss plot\n",
    "    axes[0, 0].plot(history['train_loss'], label='Train Loss')\n",
    "    axes[0, 0].plot(history['val_loss'], label='Val Loss')\n",
    "    axes[0, 0].set_title('Training and Validation Loss')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    # Accuracy plot\n",
    "    axes[0, 1].plot(history['train_acc'], label='Train Accuracy')\n",
    "    axes[0, 1].plot(history['val_acc'], label='Val Accuracy')\n",
    "    axes[0, 1].set_title('Training and Validation Accuracy')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Accuracy (%)')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True)\n",
    "    \n",
    "    # Learning rate plot\n",
    "    axes[1, 0].plot(history['lr'])\n",
    "    axes[1, 0].set_title('Learning Rate Schedule')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Learning Rate')\n",
    "    axes[1, 0].set_yscale('log')\n",
    "    axes[1, 0].grid(True)\n",
    "    \n",
    "    # Epoch time plot\n",
    "    axes[1, 1].plot(history['epoch_time'])\n",
    "    axes[1, 1].set_title('Training Time per Epoch')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Time (seconds)')\n",
    "    axes[1, 1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_predictions(model, test_loader, classes, num_samples=10):\n",
    "    \"\"\"Visualize model predictions\"\"\"\n    "    model.eval()\n    "    \n",
    "    # Get batch of test data\n",
    "    dataiter = iter(test_loader)\n",
    "    images, labels = next(dataiter)\n",
    "    \n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        images_gpu = images[:num_samples].to(device)\n",
    "        outputs = model(images_gpu)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        probs = F.softmax(outputs, dim=1)\n",
    "    \n",
    "    # Display images with predictions\n",
    "    fig = plt.figure(figsize=(20, 4))\n",
    "    \n",
    "    for idx in range(num_samples):\n",
    "        ax = fig.add_subplot(1, num_samples, idx + 1, xticks=[], yticks=[])\n",
    "        \n",
    "        # Denormalize image\n",
    "        img = images[idx].cpu().numpy().transpose(1, 2, 0)\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        img = std * img + mean\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        ax.imshow(img)\n",
    "        \n",
    "        true_label = classes[labels[idx]]\n",
    "        pred_label = classes[predicted[idx]]\n",
    "        confidence = probs[idx][predicted[idx]].item() * 100\n",
    "        \n",
    "        color = 'green' if predicted[idx] == labels[idx] else 'red'\n",
    "        ax.set_title(f'{pred_label}\\n({confidence:.1f}%)', color=color)\n",
    "        ax.text(0.5, -0.3, f'True: {true_label}', ha='center', va='top', transform=ax.transAxes)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_feature_maps(model, image_layer, layer_name, num_filters=16):\n",
    "    \"\"\"Visualize feature maps from a specific layer\"\"\"\n    "    model.eval()\n",
    "    \n",
    "    # Hook to extract features\n",
    "    activation = {}\n",
    "    def get_activation(name):\n",
    "        def hook(model, input, output):\n",
    "            activation[name] = output.detach()\n",
    "        return hook\n",
    "    \n",
    "    # Register hook\n",
    "    for name, layer in model.named_modules():\n",
    "        if name == layer_name:\n",
    "            layer.register_forward_hook(get_activation(name))\n",
    "            break\n",
    "    \n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        output = model(image_layer.unsqueeze(0).to(device))\n",
    "    \n",
    "    # Get feature maps\n",
    "    if layer_name in activation:\n",
    "        features = activation[layer_name].squeeze().cpu()\n",
    "        \n",
    "        # Plot feature maps\n",
    "        fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "        axes = axes.ravel()\n",
    "        \n",
    "        for i in range(min(num_filters, features.shape[0])):\n",
    "            axes[i].imshow(features[i], cmap='viridis')\n",
    "            axes[i].set_title(f'Filter {i}')\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Layer '{layer_name}' not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Main Training Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_training_example():\n",
    "    \"\"\"Main training example\"\"\"\n    "    \n",
    "    # Configuration\n",
    "    config = {\n",
    "        'data_dir': 'path/to/your/dataset',  # Replace with your data path\n",
    "        'model_name': 'resnet18',\n",
    "        'batch_size': 32,\n",
    "        'image_size': 224,\n",
    "        'num_epochs': 50,\n",
    "        'learning_rate': 0.001,\n",
    "        'weight_decay': 1e-4,\n",
    "        'early_stopping_patience': 10,\n",
    "        'save_dir': 'checkpoints/image_classification'\n",
    "    }\n",
    "    \n",
    "    # Load datasets\n",
    "    train_loader, val_loader, test_loader, classes = load_datasets(\n",
    "        config['data_dir'],\n",
    "        batch_size=config['batch_size'],\n",
    "        image_size=config['image_size']\n",
    "    )\n",
    "    \n",
    "    print(f\"Classes: {classes}\")\n",
    "    print(f\"Number of classes: {len(classes)}\")\n",
    "    print(f\"Training samples: {len(train_loader.dataset)}\")\n",
    "    print(f\"Validation samples: {len(val_loader.dataset)}\")\n",
    "    print(f\"Test samples: {len(test_loader.dataset)}\")\n",
    "    \n",
    "    # Create model\n",
    "    model = create_pretrained_model(\n",
    "        config['model_name'],\n",
    "        num_classes=len(classes),\n",
    "        pretrained=True\n",
    "    )\n",
    "    \n",
    "    # Print model info\n",
    "    print(f\"\\nModel: {config['model_name']}\")\n",
    "    print(f\"Trainable parameters: {count_parameters(model):,}\")\n",
    "    \n",
    "    # Setup training\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=config['learning_rate'],\n",
    "        weight_decay=config['weight_decay']\n",
    "    )\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='min',\n",
    "        factor=0.1,\n",
    "        patience=5,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # Create trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        test_loader=test_loader,\n",
    "        device=device,\n",
    "        classes=classes,\n",
    "        save_dir=config['save_dir']\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    trainer.train(\n",
    "        num_epochs=config['num_epochs'],\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        scheduler=scheduler,\n",
    "        early_stopping_patience=config['early_stopping_patience']\n",
    "    )\n",
    "    \n",
    "    # Plot training history\n",
    "    plot_training_history(trainer.history)\n",
    "    \n",
    "    # Test model\n",
    "    test_acc, test_preds, test_targets, test_probs = trainer.test()\n",
    "    \n",
    "    # Evaluate predictions\n",
    "    trainer.evaluate_predictions(test_targets, test_preds, test_probs)\n",
    "    \n",
    "    # Visualize predictions\n",
    "    visualize_predictions(model, test_loader, classes)\n",
    "    \n",
    "    return trainer\n",
    "\n",
    "# Run the example (uncomment to execute)\n",
    "# trainer = main_training_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Inference and Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier:\n",
    "    \"\"\"Image classifier for inference\"\"\"\n    "    def __init__(self, model_path, classes, device='cpu'):\n",
    "        self.device = torch.device(device)\n",
    "        self.classes = classes\n",
    "        \n",
    "        # Load model\n",
    "        self.model = self.load_model(model_path)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Setup preprocessing\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def load_model(self, model_path):\n",
    "        \"\"\"Load trained model\"\"\"\n    "        checkpoint = torch.load(model_path, map_location=self.device)\n",
    "        \n",
    "        # Recreate model architecture\n",
    "        model = create_pretrained_model('resnet18', len(self.classes), pretrained=False)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        \n",
    "        return model.to(self.device)\n",
    "    \n",
    "    def predict(self, image_path, top_k=5):\n",
    "        \"\"\"Predict single image\"\"\"\n    "        # Load and preprocess image\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        input_tensor = self.transform(image).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        # Predict\n",
    "        with torch.no_grad():\n",
    "            output = self.model(input_tensor)\n",
    "            probs = F.softmax(output, dim=1)\n",
    "            top_probs, top_indices = torch.topk(probs, top_k)\n",
    "        \n",
    "        # Format results\n",
    "        results = []\n",
    "        for prob, idx in zip(top_probs[0], top_indices[0]):\n",
    "            results.append({\n",
    "                'class': self.classes[idx],\n",
    "                'probability': prob.item() * 100\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def predict_batch(self, image_paths, top_k=5):\n",
    "        \"\"\"Predict batch of images\"\"\"\n    "        results = []\n",
    "        \n",
    "        for image_path in image_paths:\n",
    "            result = self.predict(image_path, top_k)\n",
    "            results.append({\n",
    "                'image_path': image_path,\n",
    "                'predictions': result\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def explain_prediction(self, image_path, target_class=None):\n",
    "        \"\"\"Simple explanation using Grad-CAM\"\"\"\n    "        # This is a simplified version\n",
    "        # In practice, use proper Grad-CAM implementation\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        input_tensor = self.transform(image).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        # Get prediction\n",
    "        with torch.no_grad():\n",
    "            output = self.model(input_tensor)\n",
    "            probs = F.softmax(output, dim=1)\n",
    "            predicted_class = torch.argmax(probs, dim=1).item()\n",
    "            confidence = probs[0][predicted_class].item() * 100\n",
    "        \n",
    "        return {\n",
    "            'predicted_class': self.classes[predicted_class],\n",
    "            'confidence': confidence,\n",
    "            'top_predictions': self.predict(image_path, top_k=3)\n",
    "        }\n",
    "\n",
    "def benchmark_model(model, test_loader, device):\n",
    "    \"\"\"Benchmark model performance\"\"\"\n    "    model.eval()\n",
    "    \n",
    "    total_time = 0\n",
    "    num_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, _ in tqdm(test_loader, desc='Benchmarking'):\n",
    "            data = data.to(device)\n",
    "            \n",
    "            start_time = time.time()\n",
    "            _ = model(data)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            total_time += (end_time - start_time)\n",
    "            num_samples += data.size(0)\n",
    "    \n",
    "    avg_inference_time = total_time / num_samples\n",
    "    throughput = num_samples / total_time\n",
    "    \n",
    "    print(f\"Average inference time: {avg_inference_time*1000:.2f} ms per sample\")\n",
    "    print(f\"Throughput: {throughput:.2f} samples per second\")\n",
    "    \n",
    "    return {\n",
    "        'avg_inference_time_ms': avg_inference_time * 1000,\n",
    "        'throughput_samples_per_sec': throughput\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Best Practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Techniques Covered:\n",
    "1. **Data Loading**: Custom datasets with augmentation\n",
    "2. **Model Architectures**: Custom CNNs, ResNets, and pre-trained models\n",
    "3. **Training**: Complete training pipeline with validation\n",
    "4. **Advanced Techniques**: Mixup, CutMix, Label Smoothing, Focal Loss\n",
    "5. **Transfer Learning**: Leveraging pre-trained models\n",
    "6. **Evaluation**: Comprehensive metrics and visualization\n",
    "7. **Deployment**: Inference and benchmarking\n",
    "\n",
    "### Best Practices:\n",
    "- Use proper data augmentation\n",
    "- Implement early stopping\n",
    "- Use learning rate scheduling\n",
    "- Monitor training metrics\n",
    "- Save best models\n",
    "- Use proper evaluation metrics\n",
    "- Consider model complexity vs. performance trade-offs\n",
    "- Test on diverse data\n",
    "\n",
    "### Next Steps:\n",
    "- Experiment with different architectures\n",
    "- Try advanced augmentation techniques\n",
    "- Implement ensemble methods\n",
    "- Add model interpretability\n",
    "- Deploy to production environment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}